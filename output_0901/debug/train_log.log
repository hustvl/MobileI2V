2025-11-26 19:54:23 - [1m[Sana][0m - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-11-26 19:54:23 - [1m[Sana][0m - INFO - Config: 
{
    "data": {
        "data_path": [
            "/data/shuaizhang/MobileI2V/data.csv"
        ],
        "transform_name": "resize_crop",
        "type": "VideoTextDataset",
        "image_height": 720,
        "image_width": 1280,
        "num_frames": 17,
        "frame_interval": 1,
        "caption_proportion": {
            "prompt": 1
        },
        "external_caption_suffixes": [],
        "external_clipscore_suffixes": [],
        "clip_thr_temperature": 1.0,
        "clip_thr": 0.0,
        "sort_dataset": false,
        "load_text_feat": false,
        "load_vae_feat": false,
        "transform": "default_train",
        "data_url": "default_train",
        "hq_only": false,
        "valid_num": 0,
        "data": null,
        "extra": null
    },
    "model": {
        "model": "Mobiledit_300M_P1_D16",
        "image_height": 720,
        "image_width": 1280,
        "image_size": 512,
        "mixed_precision": "fp16",
        "fp32_attention": true,
        "load_from": "/data/shuaizhang/MobileI2V/model/hybrid_371.pth",
        "resume_from": null,
        "aspect_ratio_type": "ASPECT_RATIO_512",
        "multi_scale": false,
        "pe_interpolation": 1.0,
        "micro_condition": false,
        "attn_type": "linear",
        "autocast_linear_attn": false,
        "ffn_type": "glumbconv",
        "mlp_acts": [
            "silu",
            "silu",
            null
        ],
        "mlp_ratio": 2.5,
        "use_pe": false,
        "qk_norm": true,
        "class_dropout_prob": 0.1,
        "linear_head_dim": 32,
        "cross_norm": false,
        "cfg_scale": 4,
        "guidance_type": "classifier-free",
        "pag_applied_layers": [
            14
        ],
        "extra": null
    },
    "vae": {
        "vae_type": "video-vae",
        "vae_pretrained": "/data/shuaizhang/Sana/model/video-vae",
        "weight_dtype": "bfloat16",
        "scale_factor": 0.41407,
        "vae_latent_dim": 128,
        "vae_downsample_rate": 32,
        "sample_posterior": true,
        "extra": null
    },
    "text_encoder": {
        "text_encoder_name": "/data/shuaizhang/Sana/model/Qwen2-0.5B",
        "caption_channels": 896,
        "y_norm": true,
        "y_norm_scale_factor": 0.01,
        "model_max_length": 300,
        "chi_prompt": [],
        "extra": null
    },
    "scheduler": {
        "train_sampling_steps": 1000,
        "predict_v": true,
        "noise_schedule": "linear_flow",
        "pred_sigma": false,
        "learn_sigma": true,
        "vis_sampler": "flow_euler",
        "flow_shift": 1.0,
        "weighting_scheme": "logit_normal",
        "logit_mean": 0.0,
        "logit_std": 1.0,
        "extra": null
    },
    "train": {
        "num_workers": 4,
        "seed": 1,
        "train_batch_size": 1,
        "num_epochs": 1000,
        "gradient_accumulation_steps": 1,
        "grad_checkpointing": true,
        "gradient_clip": 1.0,
        "gc_step": 1,
        "optimizer": {
            "betas": [
                0.9,
                0.999,
                0.9999
            ],
            "eps": [
                1e-30,
                1e-16
            ],
            "lr": 0.0001,
            "type": "CAMEWrapper",
            "weight_decay": 0.1
        },
        "lr_schedule": "constant",
        "lr_schedule_args": {
            "num_warmup_steps": 2000
        },
        "auto_lr": {
            "rule": "sqrt"
        },
        "ema_rate": 0.9999,
        "eval_batch_size": 16,
        "use_fsdp": false,
        "use_flash_attn": false,
        "eval_sampling_steps": 3330,
        "lora_rank": 4,
        "log_interval": 1,
        "mask_type": "null",
        "mask_loss_coef": 0.0,
        "load_mask_index": false,
        "snr_loss": false,
        "real_prompt_ratio": 1.0,
        "training_hours": 10000.0,
        "save_image_epochs": 1,
        "save_model_epochs": 500,
        "save_model_steps": 1000,
        "visualize": true,
        "null_embed_root": "output/pretrained_models/",
        "valid_prompt_embed_root": "output/tmp_embed/",
        "validation_prompts": [
            "The video features a close-up of a man with a weathered and aged appearance. His skin is darkened, possibly due to dirt or a natural skin tone, and he has a full beard and mustache. His eyes are closed, and he appears to be in a state of rest or perhaps exhaustion. The lighting in the scene is dim, with a warm glow that suggests an indoor setting, possibly a room with a low ceiling. The man's expression is one of tranquility or perhaps deep thought. The style of the video is realistic, with a focus on the man's face and the subtle details of his surroundings. The overall mood of the video is contemplative and introspective.",
            "The video features a young man with short brown hair, who is looking to the side with a slight smile on his face. He is wearing a black jacket and a blue shirt. The background is blurred, but it appears to be an outdoor setting with a building and a tree. The style of the video is casual and candid, capturing a moment in the man's life. The focus is on the man's face and expression, with the background serving as a simple backdrop. The lighting is natural, suggesting that the video was taken during the day.",
            "The video features a young woman with long brown hair, who is smiling and looking to the side. The style of the video is a close-up shot, focusing on the woman's face and upper body. The lighting is soft and warm, highlighting the woman's features and creating a pleasant atmosphere. The background is blurred, but it appears to be an indoor setting with curtains and a window. The woman's expression is relaxed and content, suggesting a positive and uplifting mood. The overall style of the video is simple and elegant, with a focus on the woman's beauty and the intimate setting.",
            "The video features a woman with blonde hair, who appears to be in a state of deep thought or sadness. She is wearing a black blazer and has her eyes closed, suggesting she is lost in her thoughts or possibly crying. The background is blurred, but it appears to be an indoor setting with a lamp and a couch, indicating that the scene might be taking place in a living room or a similar space. The overall style of the video is realistic and it seems to capture a candid moment in the woman's life.",
            "The video features a man in a tuxedo, smiling and looking to the side. The man is well-dressed, wearing a black suit with a white shirt and a black bow tie. He has short, light-colored hair and appears to be in a good mood. The background is blurred, but it seems to be an indoor setting, possibly a room with a wooden floor and walls. The lighting is soft and warm, suggesting an indoor environment. The man's expression and attire suggest a formal or celebratory occasion.",
            "This person is talking.",
            "This person is talking1.",
            "This person is talking2.",
            "This person is talking5.",
            "This person is talking10."
        ],
        "local_save_vis": true,
        "deterministic_validation": true,
        "online_metric": false,
        "eval_metric_step": 100000,
        "online_metric_dir": "metric_helper",
        "work_dir": "output/debug",
        "skip_step": 0,
        "loss_type": "huber",
        "huber_c": 0.001,
        "num_ddim_timesteps": 50,
        "w_max": 15.0,
        "w_min": 3.0,
        "ema_decay": 0.95,
        "debug_nan": false,
        "extra": null
    },
    "controlnet": null,
    "model_growth": null,
    "work_dir": "output_0901/debug",
    "resume_from": null,
    "load_from": null,
    "debug": true,
    "caching": false,
    "report_to": "tensorboard",
    "tracker_project_name": "t2i-evit-baseline",
    "name": "tmp",
    "loss_report_name": "loss"
}
2025-11-26 19:54:23 - [1m[Sana][0m - INFO - World_size: 1, seed: 1
2025-11-26 19:54:23 - [1m[Sana][0m - INFO - Initializing: DDP for training
2025-11-26 19:54:24 - [1m[Sana][0m - INFO - vae type: video-vae
2025-11-26 19:54:24 - [1m[Sana][0m - INFO - Preparing Visualization prompt embeddings...
2025-11-26 19:54:25 - [1m[Sana][0m - INFO - v-prediction: True, noise schedule: linear_flow, flow shift: 1.0, flow weighting: logit_normal, logit-mean: 0.0, logit-std: 1.0
2025-11-26 19:54:27 - [1m[Sana][0m - WARNING - use pe: False, position embed interpolation: 1.0, base size: (23, 40)
2025-11-26 19:54:27 - [1m[Sana][0m - WARNING - attention type: linear; ffn type: glumbconv; autocast linear attn: false
2025-11-26 19:54:27 - [1m[Sana][0m - INFO - [1m[32mMobiledit:Mobiledit_300M_P1_D16, Model Parameters: 267.22M[0m
2025-11-26 19:54:28 - [1m[Sana][0m - INFO - Load checkpoint from /data/shuaizhang/MobileI2V/model/hybrid_371.pth. Load ema: False.
2025-11-26 19:54:28 - [1m[Sana][0m - WARNING - Missing keys: ['pos_embed']
2025-11-26 19:54:28 - [1m[Sana][0m - WARNING - Unexpected keys: []
2025-11-26 19:54:28 - [1m[Sana][0m - INFO - Constructing dataset VideoTextDataset...
2025-11-26 19:54:28 - [1m[Sana][0m - INFO - [1m[32mDataset VideoTextDataset constructed: [0mtime: 0.04 s, length (use/ori): 12/12
2025-11-26 19:54:28 - [1m[Sana][0m - INFO - Automatically adapt lr to 0.00001 (using sqrt scaling rule).
2025-11-26 19:54:28 - [1m[Sana][0m - INFO - CAMEWrapper Optimizer: total 196 param groups, [32m196 are learnable, 0 are fix[0m. Lr group: 196 params with lr 0.00001; Weight decay group: 196 params with weight decay 0.1.
2025-11-26 19:54:28 - [1m[Sana][0m - INFO - Lr schedule: constant, num_warmup_steps:2000.
2025-11-26 19:54:28 - [1m[Sana][0m - WARNING - [1m[32mBasic Setting: [0mlr: 0.00001, bs: 1, gc: True, gc_accum_step: 1, qk norm: True, fp32 attn: True, attn type: linear, ffn type: glumbconv, text encoder: /data/shuaizhang/Sana/model/Qwen2-0.5B, precision: fp16
2025-11-26 19:55:41 - [1m[Sana][0m - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-11-26 19:55:41 - [1m[Sana][0m - INFO - Config: 
{
    "data": {
        "data_path": [
            "/data/shuaizhang/MobileI2V/data.csv"
        ],
        "transform_name": "resize_crop",
        "type": "VideoTextDataset",
        "image_height": 720,
        "image_width": 1280,
        "num_frames": 17,
        "frame_interval": 1,
        "caption_proportion": {
            "prompt": 1
        },
        "external_caption_suffixes": [],
        "external_clipscore_suffixes": [],
        "clip_thr_temperature": 1.0,
        "clip_thr": 0.0,
        "sort_dataset": false,
        "load_text_feat": false,
        "load_vae_feat": false,
        "transform": "default_train",
        "data_url": "default_train",
        "hq_only": false,
        "valid_num": 0,
        "data": null,
        "extra": null
    },
    "model": {
        "model": "Mobiledit_300M_P1_D16",
        "image_height": 720,
        "image_width": 1280,
        "image_size": 512,
        "mixed_precision": "fp16",
        "fp32_attention": true,
        "load_from": "/data/shuaizhang/MobileI2V/model/hybrid_371.pth",
        "resume_from": null,
        "aspect_ratio_type": "ASPECT_RATIO_512",
        "multi_scale": false,
        "pe_interpolation": 1.0,
        "micro_condition": false,
        "attn_type": "linear",
        "autocast_linear_attn": false,
        "ffn_type": "glumbconv",
        "mlp_acts": [
            "silu",
            "silu",
            null
        ],
        "mlp_ratio": 2.5,
        "use_pe": false,
        "qk_norm": true,
        "class_dropout_prob": 0.1,
        "linear_head_dim": 32,
        "cross_norm": false,
        "cfg_scale": 4,
        "guidance_type": "classifier-free",
        "pag_applied_layers": [
            14
        ],
        "extra": null
    },
    "vae": {
        "vae_type": "video-vae",
        "vae_pretrained": "/data/shuaizhang/Sana/model/video-vae",
        "weight_dtype": "bfloat16",
        "scale_factor": 0.41407,
        "vae_latent_dim": 128,
        "vae_downsample_rate": 32,
        "sample_posterior": true,
        "extra": null
    },
    "text_encoder": {
        "text_encoder_name": "/data/shuaizhang/Sana/model/Qwen2-0.5B",
        "caption_channels": 896,
        "y_norm": true,
        "y_norm_scale_factor": 0.01,
        "model_max_length": 300,
        "chi_prompt": [],
        "extra": null
    },
    "scheduler": {
        "train_sampling_steps": 1000,
        "predict_v": true,
        "noise_schedule": "linear_flow",
        "pred_sigma": false,
        "learn_sigma": true,
        "vis_sampler": "flow_euler",
        "flow_shift": 1.0,
        "weighting_scheme": "logit_normal",
        "logit_mean": 0.0,
        "logit_std": 1.0,
        "extra": null
    },
    "train": {
        "num_workers": 4,
        "seed": 1,
        "train_batch_size": 1,
        "num_epochs": 1000,
        "gradient_accumulation_steps": 1,
        "grad_checkpointing": true,
        "gradient_clip": 1.0,
        "gc_step": 1,
        "optimizer": {
            "betas": [
                0.9,
                0.999,
                0.9999
            ],
            "eps": [
                1e-30,
                1e-16
            ],
            "lr": 0.0001,
            "type": "CAMEWrapper",
            "weight_decay": 0.1
        },
        "lr_schedule": "constant",
        "lr_schedule_args": {
            "num_warmup_steps": 2000
        },
        "auto_lr": {
            "rule": "sqrt"
        },
        "ema_rate": 0.9999,
        "eval_batch_size": 16,
        "use_fsdp": false,
        "use_flash_attn": false,
        "eval_sampling_steps": 3330,
        "lora_rank": 4,
        "log_interval": 1,
        "mask_type": "null",
        "mask_loss_coef": 0.0,
        "load_mask_index": false,
        "snr_loss": false,
        "real_prompt_ratio": 1.0,
        "training_hours": 10000.0,
        "save_image_epochs": 1,
        "save_model_epochs": 500,
        "save_model_steps": 1000,
        "visualize": true,
        "null_embed_root": "output/pretrained_models/",
        "valid_prompt_embed_root": "output/tmp_embed/",
        "validation_prompts": [
            "The video features a close-up of a man with a weathered and aged appearance. His skin is darkened, possibly due to dirt or a natural skin tone, and he has a full beard and mustache. His eyes are closed, and he appears to be in a state of rest or perhaps exhaustion. The lighting in the scene is dim, with a warm glow that suggests an indoor setting, possibly a room with a low ceiling. The man's expression is one of tranquility or perhaps deep thought. The style of the video is realistic, with a focus on the man's face and the subtle details of his surroundings. The overall mood of the video is contemplative and introspective.",
            "The video features a young man with short brown hair, who is looking to the side with a slight smile on his face. He is wearing a black jacket and a blue shirt. The background is blurred, but it appears to be an outdoor setting with a building and a tree. The style of the video is casual and candid, capturing a moment in the man's life. The focus is on the man's face and expression, with the background serving as a simple backdrop. The lighting is natural, suggesting that the video was taken during the day.",
            "The video features a young woman with long brown hair, who is smiling and looking to the side. The style of the video is a close-up shot, focusing on the woman's face and upper body. The lighting is soft and warm, highlighting the woman's features and creating a pleasant atmosphere. The background is blurred, but it appears to be an indoor setting with curtains and a window. The woman's expression is relaxed and content, suggesting a positive and uplifting mood. The overall style of the video is simple and elegant, with a focus on the woman's beauty and the intimate setting.",
            "The video features a woman with blonde hair, who appears to be in a state of deep thought or sadness. She is wearing a black blazer and has her eyes closed, suggesting she is lost in her thoughts or possibly crying. The background is blurred, but it appears to be an indoor setting with a lamp and a couch, indicating that the scene might be taking place in a living room or a similar space. The overall style of the video is realistic and it seems to capture a candid moment in the woman's life.",
            "The video features a man in a tuxedo, smiling and looking to the side. The man is well-dressed, wearing a black suit with a white shirt and a black bow tie. He has short, light-colored hair and appears to be in a good mood. The background is blurred, but it seems to be an indoor setting, possibly a room with a wooden floor and walls. The lighting is soft and warm, suggesting an indoor environment. The man's expression and attire suggest a formal or celebratory occasion.",
            "This person is talking.",
            "This person is talking1.",
            "This person is talking2.",
            "This person is talking5.",
            "This person is talking10."
        ],
        "local_save_vis": true,
        "deterministic_validation": true,
        "online_metric": false,
        "eval_metric_step": 100000,
        "online_metric_dir": "metric_helper",
        "work_dir": "output/debug",
        "skip_step": 0,
        "loss_type": "huber",
        "huber_c": 0.001,
        "num_ddim_timesteps": 50,
        "w_max": 15.0,
        "w_min": 3.0,
        "ema_decay": 0.95,
        "debug_nan": false,
        "extra": null
    },
    "controlnet": null,
    "model_growth": null,
    "work_dir": "output_0901/debug",
    "resume_from": null,
    "load_from": null,
    "debug": true,
    "caching": false,
    "report_to": "tensorboard",
    "tracker_project_name": "t2i-evit-baseline",
    "name": "tmp",
    "loss_report_name": "loss"
}
2025-11-26 19:55:41 - [1m[Sana][0m - INFO - World_size: 1, seed: 1
2025-11-26 19:55:41 - [1m[Sana][0m - INFO - Initializing: DDP for training
2025-11-26 19:55:42 - [1m[Sana][0m - INFO - vae type: video-vae
2025-11-26 19:55:42 - [1m[Sana][0m - INFO - v-prediction: True, noise schedule: linear_flow, flow shift: 1.0, flow weighting: logit_normal, logit-mean: 0.0, logit-std: 1.0
2025-11-26 19:55:44 - [1m[Sana][0m - WARNING - use pe: False, position embed interpolation: 1.0, base size: (23, 40)
2025-11-26 19:55:44 - [1m[Sana][0m - WARNING - attention type: linear; ffn type: glumbconv; autocast linear attn: false
2025-11-26 19:55:44 - [1m[Sana][0m - INFO - [1m[32mMobiledit:Mobiledit_300M_P1_D16, Model Parameters: 267.22M[0m
2025-11-26 19:55:45 - [1m[Sana][0m - INFO - Load checkpoint from /data/shuaizhang/MobileI2V/model/hybrid_371.pth. Load ema: False.
2025-11-26 19:55:45 - [1m[Sana][0m - WARNING - Missing keys: ['pos_embed']
2025-11-26 19:55:45 - [1m[Sana][0m - WARNING - Unexpected keys: []
2025-11-26 19:55:45 - [1m[Sana][0m - INFO - Constructing dataset VideoTextDataset...
2025-11-26 19:55:45 - [1m[Sana][0m - INFO - [1m[32mDataset VideoTextDataset constructed: [0mtime: 0.00 s, length (use/ori): 12/12
2025-11-26 19:55:45 - [1m[Sana][0m - INFO - Automatically adapt lr to 0.00001 (using sqrt scaling rule).
2025-11-26 19:55:45 - [1m[Sana][0m - INFO - CAMEWrapper Optimizer: total 196 param groups, [32m196 are learnable, 0 are fix[0m. Lr group: 196 params with lr 0.00001; Weight decay group: 196 params with weight decay 0.1.
2025-11-26 19:55:45 - [1m[Sana][0m - INFO - Lr schedule: constant, num_warmup_steps:2000.
2025-11-26 19:55:45 - [1m[Sana][0m - WARNING - [1m[32mBasic Setting: [0mlr: 0.00001, bs: 1, gc: True, gc_accum_step: 1, qk norm: True, fp32 attn: True, attn type: linear, ffn type: glumbconv, text encoder: /data/shuaizhang/Sana/model/Qwen2-0.5B, precision: fp16
2025-11-26 19:55:51 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 1 | Local Step: 1 // 12, total_eta: 16:52:24, epoch_eta:0:00:55, time: all:5.063, model:1.057, data:1.643, lm:0.358, vae:2.002, lr:3.125e-09, loss:0.5387, grad_norm:4.4952
2025-11-26 19:55:51 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 2 | Local Step: 2 // 12, total_eta: 9:49:20, epoch_eta:0:00:29, time: all:0.832, model:0.456, data:0.001, lm:0.033, vae:0.337, lr:6.250e-09, loss:0.5678, grad_norm:4.4894
2025-11-26 19:55:52 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 3 | Local Step: 3 // 12, total_eta: 7:26:59, epoch_eta:0:00:20, time: all:0.812, model:0.437, data:0.000, lm:0.033, vae:0.339, lr:9.375e-09, loss:0.5954, grad_norm:4.5344
2025-11-26 19:55:53 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 4 | Local Step: 4 // 12, total_eta: 6:16:14, epoch_eta:0:00:15, time: all:0.821, model:0.445, data:0.001, lm:0.034, vae:0.338, lr:1.250e-08, loss:0.5323, grad_norm:4.0366
2025-11-26 19:55:54 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 5 | Local Step: 5 // 12, total_eta: 5:33:41, epoch_eta:0:00:11, time: all:0.818, model:0.438, data:0.000, lm:0.038, vae:0.339, lr:1.563e-08, loss:0.5254, grad_norm:4.0171
2025-11-26 19:55:55 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 6 | Local Step: 6 // 12, total_eta: 5:05:22, epoch_eta:0:00:09, time: all:0.820, model:0.445, data:0.000, lm:0.033, vae:0.339, lr:1.875e-08, loss:0.5271, grad_norm:4.4343
2025-11-26 19:55:56 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 7 | Local Step: 7 // 12, total_eta: 4:45:39, epoch_eta:0:00:07, time: all:0.838, model:0.455, data:0.000, lm:0.041, vae:0.340, lr:2.188e-08, loss:0.5372, grad_norm:4.4068
2025-11-26 19:55:56 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 8 | Local Step: 8 // 12, total_eta: 4:30:28, epoch_eta:0:00:05, time: all:0.822, model:0.444, data:0.000, lm:0.034, vae:0.340, lr:2.500e-08, loss:0.5255, grad_norm:4.4164
2025-11-26 19:55:57 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 9 | Local Step: 9 // 12, total_eta: 4:18:15, epoch_eta:0:00:03, time: all:0.804, model:0.418, data:0.000, lm:0.039, vae:0.344, lr:2.812e-08, loss:0.5246, grad_norm:4.2871
2025-11-26 19:55:57 - [1m[Sana][0m - INFO - Running validation... 
2025-11-26 19:56:52 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 10 | Local Step: 10 // 12, total_eta: 22:00:19, epoch_eta:0:00:13, time: all:54.445, model:0.355, data:0.001, lm:0.039, vae:0.357, lr:2.812e-08, loss:0.5095, grad_norm:inf
2025-11-26 19:56:53 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 11 | Local Step: 11 // 12, total_eta: 20:15:34, epoch_eta:0:00:06, time: all:0.846, model:0.455, data:0.001, lm:0.040, vae:0.347, lr:3.125e-08, loss:0.5558, grad_norm:3.9019
2025-11-26 19:56:53 - [1m[Sana][0m - INFO - Epoch: 1 | Global Step: 12 | Local Step: 12 // 12, total_eta: 18:48:16, epoch_eta:0:00:00, time: all:0.847, model:0.457, data:0.000, lm:0.039, vae:0.347, lr:3.438e-08, loss:0.5279, grad_norm:3.7696
2025-11-26 19:56:56 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 13 | Local Step: 1 // 12, total_eta: 8:57:54, epoch_eta:0:00:29, time: all:2.693, model:0.457, data:1.835, lm:0.045, vae:0.354, lr:3.750e-08, loss:0.5407, grad_norm:4.1812
2025-11-26 19:56:57 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 14 | Local Step: 2 // 12, total_eta: 5:51:58, epoch_eta:0:00:17, time: all:0.831, model:0.447, data:0.000, lm:0.034, vae:0.347, lr:4.063e-08, loss:0.4877, grad_norm:4.4022
2025-11-26 19:56:58 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 15 | Local Step: 3 // 12, total_eta: 4:51:06, epoch_eta:0:00:13, time: all:0.848, model:0.457, data:0.001, lm:0.040, vae:0.347, lr:4.375e-08, loss:0.5081, grad_norm:3.8835
2025-11-26 19:56:59 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 16 | Local Step: 4 // 12, total_eta: 4:19:49, epoch_eta:0:00:10, time: all:0.831, model:0.445, data:0.001, lm:0.035, vae:0.347, lr:4.688e-08, loss:0.4861, grad_norm:3.8234
2025-11-26 19:56:59 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 17 | Local Step: 5 // 12, total_eta: 3:59:27, epoch_eta:0:00:08, time: all:0.791, model:0.409, data:0.000, lm:0.035, vae:0.345, lr:5.000e-08, loss:0.4856, grad_norm:3.8351
2025-11-26 19:57:00 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 18 | Local Step: 6 // 12, total_eta: 3:45:29, epoch_eta:0:00:06, time: all:0.780, model:0.408, data:0.000, lm:0.025, vae:0.345, lr:5.313e-08, loss:0.4975, grad_norm:3.3723
2025-11-26 19:57:01 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 19 | Local Step: 7 // 12, total_eta: 3:35:23, epoch_eta:0:00:05, time: all:0.776, model:0.406, data:0.000, lm:0.022, vae:0.345, lr:5.625e-08, loss:0.4706, grad_norm:3.4426
2025-11-26 19:57:01 - [1m[Sana][0m - INFO - Running validation... 
2025-11-26 19:57:56 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 20 | Local Step: 8 // 12, total_eta: 1 day, 1:47:58, epoch_eta:0:00:31, time: all:54.476, model:0.457, data:0.001, lm:0.040, vae:0.360, lr:5.938e-08, loss:0.4557, grad_norm:4.6431
2025-11-26 19:57:56 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 21 | Local Step: 9 // 12, total_eta: 23:14:41, epoch_eta:0:00:20, time: all:0.849, model:0.457, data:0.000, lm:0.039, vae:0.349, lr:6.250e-08, loss:0.4902, grad_norm:3.3824
2025-11-26 19:57:57 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 22 | Local Step: 10 // 12, total_eta: 21:12:07, epoch_eta:0:00:12, time: all:0.852, model:0.459, data:0.000, lm:0.040, vae:0.349, lr:6.563e-08, loss:0.4596, grad_norm:2.9663
2025-11-26 19:57:58 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 23 | Local Step: 11 // 12, total_eta: 19:31:52, epoch_eta:0:00:05, time: all:0.854, model:0.461, data:0.000, lm:0.040, vae:0.349, lr:6.875e-08, loss:0.4468, grad_norm:3.8239
2025-11-26 19:57:59 - [1m[Sana][0m - INFO - Epoch: 2 | Global Step: 24 | Local Step: 12 // 12, total_eta: 18:08:50, epoch_eta:0:00:00, time: all:0.885, model:0.464, data:0.000, lm:0.066, vae:0.351, lr:7.188e-08, loss:0.4503, grad_norm:2.6736
2025-11-26 19:58:02 - [1m[Sana][0m - INFO - Epoch: 3 | Global Step: 25 | Local Step: 1 // 12, total_eta: 10:30:04, epoch_eta:0:00:34, time: all:3.157, model:0.452, data:2.307, lm:0.037, vae:0.360, lr:7.500e-08, loss:0.4377, grad_norm:2.5700
2025-11-26 19:58:03 - [1m[Sana][0m - INFO - Epoch: 3 | Global Step: 26 | Local Step: 2 // 12, total_eta: 6:37:23, epoch_eta:0:00:19, time: all:0.825, model:0.439, data:0.000, lm:0.035, vae:0.348, lr:7.813e-08, loss:0.4244, grad_norm:2.3204
2025-11-26 19:58:04 - [1m[Sana][0m - INFO - Epoch: 3 | Global Step: 27 | Local Step: 3 // 12, total_eta: 5:20:22, epoch_eta:0:00:14, time: all:0.834, model:0.449, data:0.001, lm:0.034, vae:0.348, lr:8.125e-08, loss:0.4213, grad_norm:2.2170
2025-11-26 19:58:05 - [1m[Sana][0m - INFO - Epoch: 3 | Global Step: 28 | Local Step: 4 // 12, total_eta: 4:40:12, epoch_eta:0:00:11, time: all:0.801, model:0.415, data:0.001, lm:0.033, vae:0.349, lr:8.437e-08, loss:0.4408, grad_norm:2.3157
2025-11-26 19:58:05 - [1m[Sana][0m - INFO - Epoch: 3 | Global Step: 29 | Local Step: 5 // 12, total_eta: 4:15:21, epoch_eta:0:00:08, time: all:0.782, model:0.409, data:0.000, lm:0.023, vae:0.347, lr:8.750e-08, loss:0.4201, grad_norm:2.2886
2025-11-26 19:58:05 - [1m[Sana][0m - INFO - Running validation... 
